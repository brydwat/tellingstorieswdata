---
title: "tswd_ch6_notes"
author: "Bryce Watson"
date: "2024-11-29"
output:
  html_document:
    theme:
      bootswatch: cerulean
---

```{r, warning=FALSE, message=FALSE}
# Load packages

library(cancensus)
library(canlang)
library(maps)
library(tidycensus)
library(tidyverse)
library(tinytable)
```

# 6.1 Introduction

Farmed Data - typically well put together, thoroughly documented, and the work of collecting, preparing, and cleaning these datasets is mostly done for us.

The state’s desire for legibility also required imposing consistency on measurement. The modern form of metrology, which is “the study of how measurements are made, and how data are compared” (Plant and Hanisch 2020), began in the French Revolution when various measurements were standardized. This later further developed as part of Napoleonic state building

The essence of the change as one where knowledge went from being “singular, local, idiosyncratic and often couched in literary form” to generalized, standardized, and numeric.

A further concern is reification, where we forget that these measures must be constructed.

John Mill wrote a history of India and said you could learn more from a book than visiting. People continue to use statistics without trying to build them or understand them. "We should always throw ourselves into the details of the data."

# 6.2 Measurement

Measurement: measurement as the “process of experimentally obtaining one or more quantity values that can reasonably be attributed to a quantity”, where a quantity is a “number and reference together”. It implies “comparison of quantities, including counting of entities”, and “presupposes a description of the quantity commensurate with the intended use of a measurement result, a measurement procedure, and a calibrated measuring system"

Measurement error is the difference between the value we observe and the actual value.

Right-censored data: Roentgen measurement after Chernobyl, maxed at 3.5, but real number was much higher than limit (censored above limit).

Left-censored data: Thermometer's minimum is freezing, but real value is lower than limit (censored below limit).

Winsorizing data: Changing an observed value to a less extreme one. For example counting all over 100 years as 100 years old as a very large value might skew significance. Truncated data is slightly different situation where we do not even record outliers.

\> Benefits of winsorizing vs truncating vs removing outliers?

```{r, echo=FALSE, warning=FALSE}
newborn_weight <-
  tibble(
    weight = rep(
      x = rnorm(n = 1000, mean = 3.5, sd = 0.5), 
      times = 3),
    measurement = rep(
      x = c("Actual", "Censored", "Truncated"),
      each = 1000)
    )

newborn_weight <-
  newborn_weight |>
  mutate(
    weight = case_when(
      weight <= 2.75 & measurement == "Censored" ~ 2.75,
      weight >= 4.25 & measurement == "Truncated" ~ NA_real_,
      TRUE ~ weight
    )
  )


newborn_weight |>
  ggplot(aes(x = weight)) +
  geom_histogram(bins = 50) +
  facet_wrap(vars(measurement)) +
  theme_minimal()
```

Regardless of how well data is collected, there will be missing data... A variable must be measured, or at least thought about and considered, in order to be missing. With insufficient consideration, there is the danger of missing data that we do not even know are missing because the variables were never considered. 

Non-response could be considered a variant of measurement error whereby we observe a null, even though there should be an actual value. 

Non-response is a key issue, especially with non-probability samples, because there is usually good reason to consider that people who do not respond are systematically different to those who do.

In an ideal situation data are Missing Completely At Random (MCAR) - rare if possible. More likely Missing at Random (MAR) or missing not at random (MNAR)

# 6.4 Sampling essentials
“Statistics is the science of how to collect and analyze data and draw statements and conclusions about unknown populations.” - Wu and Thompson, 2020

 1. “Target population”: The collection of all items about which we would like to speak.
 2. “Sampling frame”: A list of all the items from the target population that we could get data about.
 3. “Sample”: The items from the sampling frame that we get data about.
 
Probabalistic Sampling
 1. “Probability sampling”: Every unit in the sampling frame has some known chance of being sampled and the specific sample is obtained randomly based on these chances. The chance of being sampled does not necessarily need to be same for each unit.
 2. “Non-probability sampling”: Units from the sampling frame are sampled based on convenience, quotas, judgement, or other non-random processes.
 
 Four types of probability sampling
  1. Simple random - every unit has the same chance of being included
 
  2. Systematic - proceed by selecting some value, and we then sample every X unit to obtain a Y per cent sample.
  
  3. Stratified -  which we can divide the population into mutually exclusive, and collectively exhaustive, sub-populations called “strata” (age, county, state, class, etc).
 
  4. Cluster -  Like strata, clusters are collectively exhaustive and mutually exclusive. Specifically, with cluster sampling, we do not intend to collect data from every cluster, whereas with stratified sampling we do.
  
  Three types of non-probability sampling
  1. Convenience Sampling - 
  2. Quota Sampling - 
  3. Respondent-driven Sampling - 
  
  
  Quote from LRoB
  "This always entails some ‘sacrifice’ of fine-grained local information, and hence often encounters stiff opposition from specialists accustomed to assay every detail with a jeweler’s balance: doctors who balk at neglecting the clinical peculiarities of a case in favour of statistically evaluated therapies;"
  Applies to
  Doctors vs Epidemiologists.
  
  "The conditions of equivalence can be political as well as conceptual. Even an exercise as apparently straightforward as conducting a national census presupposes classes of equivalence. When, for example, the first US Census, mandated by the Constitution at ten-year intervals to apportion seats among the States in the House of Representatives, was conducted in 1790, slaves were counted as three-fifths of a free man."
  
  
  "Coding – the assignment of an individual case to a class of equivalence – is usually treated as a mechanical task, farmed out to unskilled, badly-paid minions in statistical offices. But Desrosières reveals its complexities and importance: this is the juncture at which the critical work of abstraction that anchors statistical classes to the world must be done, over and over again."
  
Task II
```{r}
# Simulate UK Biobank data
set.seed(234)




```
